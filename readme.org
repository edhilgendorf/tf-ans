#+TITLE: Deploying a Web App with AWS, Terraform, Cloud-init, Ansible and Jenkins
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+EXPORT_FILE_NAME: index.html
See: https://edhilgendorf.github.io/tf-ans/
* The project
Project is to use this repository ( and possibly a couple others ) to build and deploy a web application using some core technologies:
** Technologies used
*** DONE AWS for cloud housting
- [[*Configure AWS][Configure AWS]]
*** DONE GitHub to host code, configs, and static site: https://edhilgendorf.github.io/tf-ans/
*** DONE Terraform Cloud ( free ) to handle state and Terrafrom deployments upon check-in with GitHub
- [[*Configure Terraform Cloud][Configure Terraform Cloud]]
*** Terraform to provision AWS
 + [[#-create-infrastructure-with-terraform-][Create Infrastructure with Terraform]]
*** TODO Cloud-init for any VMs
 + [[*Bootstrap EC2 with cloud-init][Bootstrap EC2 with cloud-init]]
*** Ansible for config management
+ [[*Configuration Management with Ansible][Configuration Management with Ansible]] on [[#-create-infrastructure-with-terraform-ecs-for-awx-][ECS for AWX]]
*** Jenkins to deploy the application
+ An application /(TBD)/ inside a Docker Container
+ Ansible to Deploy Kubernetes
** This Document
Documentation and code are built into this same [[https://orgmode.org/][orgmode]] document. All the code in this repository is created from snippets in this document via org-tangle. The process is as follows:
1. Create a new bullet point/update old one
2. Add ~PROPERTIES~ under the bullet to specify file to either ammend or create
3. Run ~org-bable-tangle~ (within Emacs). This extracts all code blocks and builds code files
4. /optional/ Apply any necessary formatting, ex: ~terraform fmt~
5. Check in and push changes. This document and corresponding repositories *should* be VCS driven, with changes applied after successful Git commit/push.
The purpose of this is to build a cloud based project using IaC that explains *why* each step is done, as well as *how*, all in one place. See this document in plain text, here: [[https://raw.githubusercontent.com/edhilgendorf/tf-ans/main/readme.org][readme.org]]
** Links
- [[https://github.com/edhilgendorf/tf-ans][Terraform Project Repository]]
- [[https://github.com/edhilgendorf/ansible-cloud][Ansible Project Repository]]
- [[https://edhilgendorf.github.io/tf-ans/][Read the docs]]
- [[https://hilgendorf.me][hilgendorf.me]]
** Challenges
- Secrets :: The idea is this entire document and project are available so anyone can see how it is setup and the output at the end. This means no plaintext passwords and having to be carefeul with key-pairs.
- VCS Driven from Terraform Cloud :: This has been the most difficult. I have seen before, and do not want to end up with a situation where you have to run Bash/etc scripts from different locations to get to the required end-state, so I decided to use VCS as "single source of truth" and have all Terraform deployed from Terraform Cloud. This rules out a lot of things: using Terraform outputs in Ansible/etc scripts, as well as using local provisioners. That being said, Terraform recommends against local-exec provisioners so I think it's a good step, regardless.
** Conventions :conventions:
*** Code Example :example:
- Each block will be named as above
- Following will be bullet points with an explanation and /hopefully/ a link to the corresponding resource
**** [[./terraform/example_code.py]] <-- the file that will be "tangled", see [[*This Document][This Document]]
:PROPERTIES:
:header-args: :tangle terraform/example_code.py
:END:
- This prints "hello world" to the user on execution
  #+begin_src python
print ("hello world")
print("1")
  #+end_src
*** File structure
- Since Terraform runs are repo driven, anytime an update hits it will queue up a run. In order to save money on AWS, and lower the number of runs, create a working directory in Terraform Cloud, then relocate all Terraform code to that directory.
  + https://www.terraform.io/docs/cloud/workspaces/settings.html
- It is then possible to trigger runs only on working directories
- This also prevents Terraform kicking off when I am only updating this documentation.
- Real file structure will look like this:
  #+begin_src
.
├── ansible-cloud
│   ├── ansible.cfg
│   ├── inventory
│   └── README.md
└── terraform-cloud
    ├── example_code.py
    ├── index.html
    ├── readme.org
    └── terraform
  #+end_src
  + This structure is rigid as I may want to experiment getting outputs from Terraform into Ansible. But I don't think this is best practice (to be done locally) as Git checkouts/clones can vary by user. I think one solution is a Git submodule, or just using terraform ~local-exec~ to clone in place, but as mentioned in [[https://www.terraform.io/docs/language/resources/provisioners/local-exec.html][local-exec provisioner documentation]] it is a last resort.
* Install Terraform :terraform:install:
https://www.terraform.io/downloads.html
* Install Packer -- (Unused in this project, at this time) :packer:install:
#+begin_src bash
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
sudo apt-get update && sudo apt-get install packer
#+end_src
* Configure AWS :aws:
- Register account: https://portal.aws.amazon.com/gp/aws/developer/registration/index.html
** Setup AWS CLI :cli:install:
- https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html
** Use AWS CLI :cli:
** Create IAM User and Policies :iam:
:PROPERTIES:
:CUSTOM_ID: -configure-aws-create-iam-user-and-policies-
:END:
- IAM: https://console.aws.amazon.com/iam/home
- Polcies: https://console.aws.amazon.com/iamv2/home?#/policiesC
- IAM User: https://console.aws.amazon.com/iam/home#/users$new?step=details
  + programmatic (non-console)
  + attach existing policy
- Add user to ~/.aws/credentials~ as a profile:
 #+begin_src
 [default]
 aws_access_key=<your_key>
 aws_secret_access_key=<your_key>

 [tf_user]
 aws_access_key=<your_key>
 aws_secret_access_key=<your_key>
 #+end_src
- Add root user as default, or create IAM admin:
  https://console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials$access_key
*** IAM Terraform User _start_ :policy:
**** [[./terraform/policies/terraform_user.json]]
:PROPERTIES:
:header-args: :tangle terraform/policies/terraform_user.json
:END:
- this is very much a WIP, and some of these are *wide* open, such as IAM while working through issues.
- I am splitting this up so that each terraform module used get's it's IAM actions in the same bullet point/section.
- See [[#-iam-terraform-user--end--][IAM Terraform User _end_]]
#+begin_src json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "CustomPolicyForACGAWSTFCourse",
      "Action": [
        "ec2:Describe*",
        "ec2:Get*",
        "ec2:AcceptVpcPeeringConnection",
        "ec2:AttachInternetGateway",
        "ec2:AssociateRouteTable",
        "ec2:AssociateIamInstanceProfile",
        "ec2:AuthorizeSecurityGroupEgress",
        "ec2:AuthorizeSecurityGroupIngress",
        "ec2:CreateInternetGateway",
        "ec2:CreateNetworkAcl",
        "ec2:CreateNetworkAclEntry",
        "ec2:CreateRoute",
        "ec2:CreateRouteTable",
        "ec2:CreateSecurityGroup",
        "ec2:CreateSubnet",
        "ec2:CreateTags",
        "ec2:CreateVpc",
        "ec2:CreateVpcPeeringConnection",
        "ec2:DeleteNetworkAcl",
        "ec2:DeleteNetworkAclEntry",
        "ec2:DeleteRoute",
        "ec2:DeleteRouteTable",
        "ec2:DeleteSecurityGroup",
        "ec2:DeleteSubnet",
        "ec2:DeleteTags",
        "ec2:DeleteVpc",
        "ec2:DeleteVpcPeeringConnection",
        "ec2:DetachInternetGateway",
        "ec2:DisassociateRouteTable",
        "ec2:DisassociateSubnetCidrBlock",
        "ec2:CreateKeyPair",
        "ec2:DeleteKeyPair",
        "ec2:DeleteInternetGateway",
        "ec2:ImportKeyPair",
        "ec2:ModifySubnetAttribute",
        "ec2:ModifyVpcAttribute",
        "ec2:ModifyVpcPeeringConnectionOptions",
        "ec2:RejectVpcPeeringConnection",
        "ec2:ReplaceNetworkAclAssociation",
        "ec2:ReplaceNetworkAclEntry",
        "ec2:ReplaceRoute",
        "ec2:ReplaceRouteTableAssociation",
        "ec2:RevokeSecurityGroupEgress",
        "ec2:RevokeSecurityGroupIngress",
        "ec2:RunInstances",
        "ec2:TerminateInstances",
        "ec2:UpdateSecurityGroupRuleDescriptionsEgress",
        "ec2:UpdateSecurityGroupRuleDescriptionsIngress",
        "acm:*",
        "elasticloadbalancing:AddListenerCertificates",
        "elasticloadbalancing:AddTags",
        "elasticloadbalancing:CreateListener",
        "elasticloadbalancing:CreateLoadBalancer",
        "elasticloadbalancing:CreateRule",
        "elasticloadbalancing:CreateTargetGroup",
        "elasticloadbalancing:DeleteListener",
        "elasticloadbalancing:DeleteLoadBalancer",
        "elasticloadbalancing:DeleteRule",
        "elasticloadbalancing:DeleteTargetGroup",
        "elasticloadbalancing:DeregisterTargets",
        "elasticloadbalancing:DescribeListenerCertificates",
        "elasticloadbalancing:DescribeListeners",
        "elasticloadbalancing:DescribeLoadBalancerAttributes",
        "elasticloadbalancing:DescribeLoadBalancers",
        "elasticloadbalancing:DescribeRules",
        "elasticloadbalancing:DescribeSSLPolicies",
        "elasticloadbalancing:DescribeTags",
        "elasticloadbalancing:DescribeTargetGroupAttributes",
        "elasticloadbalancing:DescribeTargetGroups",
        "elasticloadbalancing:DescribeTargetHealth",
        "elasticloadbalancing:ModifyListener",
        "elasticloadbalancing:ModifyLoadBalancerAttributes",
        "elasticloadbalancing:ModifyRule",
        "elasticloadbalancing:ModifyTargetGroup",
        "elasticloadbalancing:ModifyTargetGroupAttributes",
        "elasticloadbalancing:RegisterTargets",
        "elasticloadbalancing:RemoveListenerCertificates",
        "elasticloadbalancing:RemoveTags",
        "elasticloadbalancing:SetSecurityGroups",
        "elasticloadbalancing:SetSubnets",
        "route53:Get*",
        "route53:List*",
        "route53:ChangeResourceRecordSets",
        "ssm:Describe*",
        "ssm:GetParameter",
        "ssm:GetParameters",
        "ssm:GetParametersByPath",
        "s3:CreateBucket",
        "s3:*",
        "s3:DeleteBucket",
        "s3:DeleteObject",
        "s3:GetBucketLocation",
        "s3:GetObject",
        "s3:HeadBucket",
        "s3:ListBucket",
        "iam:*",
        "s3:PutObject"
#+end_src
* Configure Terraform Cloud :cloud:terraform_cloud:
- Regsiter account: https://app.terraform.io/signup/account?utm_source=terraform_io&utm_content=terraform_cloud_top_nav
- Create an organization
- Create a Workspace from VCS Repository, ex: https://github.com
- Create a token and save in ~~/.terraform.d/credentials.tfrc.json~
  - https://app.terraform.io/app/settings/tokens
- Add access keys to Terraform Cloud
  - https://app.terraform.io/app/<organization>/workspaces/<workspace>/variables
- Initialize your environment ~terraform init~
- Configure Terraform Cloud to plan and apply upon check-in
  + https://app.terraform.io/app/<your_org>/workspaces/<your_workspace>/settings/general
- setup a backend remote pointing to your org/workspace
** [[./terraform/backend.tf]]
:PROPERTIES:
:header-args: :tangle terraform/backend.tf
:END:
#+begin_src json
terraform {
  backend "remote" {
    organization = "hilgendorfdotme"
    workspaces {
      name = "tf-ans"
    }
  }
}
#+end_src
* Create Infrastructure with Terraform :terraform:iac:
:PROPERTIES:
:CUSTOM_ID: -create-infrastructure-with-terraform-
:END:
** Configure Providers
*** [[./terraform/providers.tf]]
:PROPERTIES:
:header-args: :tangle terraform/providers.tf
:END:
#+begin_src json
provider "aws" {
  #profile = var.profile
  region = var.region-master
  alias  = "region-master"
}

provider "aws" {
  #profile = var.profile
  region = var.region-worker
  alias  = "region-worker"
}
#+end_src
** Create variables :variables:
- Input variables serve as parameters for a Terraform module, allowing aspects of the module to be customized without altering the module's own source code, and allowing modules to be shared between different configurations.
  + https://www.terraform.io/docs/language/values/variables.html
*** [[./terraform/variables.tf]]
:PROPERTIES:
:header-args: :tangle terraform/variables.tf
:END:
- profile and default user
- two regions
  - a master region (us-east-1)
  - a worker region (us-west-2)
- external ip (yours)
- workers count (how many instances to create)
- instance type when deploying EC2
- a URL for our Ansible repo so we can clone it
- set IAM policy for EC2 Full access, this will be used for Ansible [[*Dynamic Inventory][Dynamic Inventory]]
#+begin_src json
variable "profile" {
  type    = string
  default = "tf_user"
}
variable "region-master" {
  type    = string
  default = "us-east-1"
}
variable "region-worker" {
  type    = string
  default = "us-west-2"
}
variable "test" {
  type    = string
  default = "catheadbiscuit"
}
#Replace with <YOUR_EXTERNAL_IP>  https://ipv4.icanhazip.com
variable "external_ip" {
  type    = string
  default = "0.0.0.0/0"
}
variable "workers-count" {
  type    = number
  default = 1
}
variable "instance-type" {
  type    = string
  default = "t3.micro"
}
variable "ansible-git" {
  type    = string
  default = "https://github.com/edhilgendorf/ansible-cloud.git"
}
variable "iam_policy_ec2_full_arn" {
  description = "IAM Policy for full EC2"
  type = string
  default = "arn:aws:iam::aws:policy/AmazonEC2FullAccess"
}
#+end_src
** Create a network :network:
*** Create VPCs :vpc:
- A virtual network dedicated to your AWS account.
  + https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html
**** [[./terraform/network.tf]]
:PROPERTIES:
:header-args: :tangle terraform/network.tf
:END:
+ VPCs
  - *vpc_master*
    + deploy in us-east-1
    + give network 10.0.0.0/16
    + enable dns and hostnames
    + tag this as ~master-vpc-devops~
  - *vpc_master_oregon*
    + deploy in us-west-2
    + give network 192.168.0.0/16
    + enable dns and hostnames
    + tag as ~worker-vpc-devops~
+ Variables come from: [[*Create variables][Create variables]]
#+begin_src json
#Create VPC in us-east-1
resource "aws_vpc" "vpc_master" {
  provider             = aws.region-master
  cidr_block           = "10.0.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true
  tags = {
    Name = "master-vpc-devops"
  }
}
#Create VPC in us-west-2
resource "aws_vpc" "vpc_master_oregon" {
  provider             = aws.region-worker
  cidr_block           = "192.168.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true
  tags = {
    Name = "worker-vpc-devops"
  }
}
  #+end_src
*** Create IGWs :igw:
- An internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between your VPC and the internet.
  + https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html
**** [[./terraform/network.tf]]
:PROPERTIES:
:header-args: :tangle terraform/network.tf
:END:
+ create an internet gateway in each VPC, which reside in different availability zones (us-east-1 and us-west-2)
#+begin_src json
#Create IGW in us-east-1
resource "aws_internet_gateway" "igw" {
  provider = aws.region-master
  vpc_id   = aws_vpc.vpc_master.id
}
#Create IGW in us-west-2
resource "aws_internet_gateway" "igw-oregon" {
  provider = aws.region-worker
  vpc_id   = aws_vpc.vpc_master_oregon.id
}
#+end_src
*** Provide Data :data:
- Data sources allow Terraform use information defined outside of Terraform, defined by another separate Terraform configuration, or modified by functions.
  + https://www.terraform.io/docs/language/data-sources/index.html
**** [[./terraform/network.tf]]
  :PROPERTIES:
  :header-args: :tangle terraform/network.tf
  :END:
  + get ~aws_availability_zones~ that are in ~state: available~
  #+begin_src json
#get all available AZs in VPC for master
data "aws_availability_zones" "azs" {
  provider = aws.region-master
  state    = "available"
}
  #+end_src
*** Create Subnets in our VPCs :subnet:
- When you create a VPC, you must specify a range of IPv4 addresses for the VPC in the form of a Classless Inter-Domain Routing (CIDR) block; for example, 10.0.0.0/16. This is the primary CIDR block for your VPC. For more information about CIDR notation, see RFC 4632.
  + https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html
**** [[./terraform/network.tf]]
:PROPERTIES:
  :header-args: :tangle terraform/network.tf
  :END:
+ two subnets in the master VPC defined in [[*Create VPCs][Create VPCs]].
  - ~10.0.1.0/24~
  - ~10.0.2.0/24~
+ one subnet in the worker VPC defined in  [[*Create VPCs][Create VPCs]].
  - ~192.168.1.0/24~
#+begin_src json
  #create subnet #1 in us-east-1
  resource "aws_subnet" "subnet_1" {
    provider          = aws.region-master
    availability_zone = element(data.aws_availability_zones.azs.names, 0)
    vpc_id            = aws_vpc.vpc_master.id
    cidr_block        = "10.0.1.0/24"
  }
  #create subnet #2 in us-east-1
  resource "aws_subnet" "subnet_2" {
    provider          = aws.region-master
    availability_zone = element(data.aws_availability_zones.azs.names, 1)
    vpc_id            = aws_vpc.vpc_master.id
    cidr_block        = "10.0.2.0/24"
  }
  #create subnet #1 in us-west-2
  resource "aws_subnet" "subnet_1_oregon" {
    provider   = aws.region-worker
    vpc_id     = aws_vpc.vpc_master_oregon.id
    cidr_block = "192.168.1.0/24"
  }
#+end_src
*** Create Peering between VPCs :peering:
- A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them using private IPv4 addresses or IPv6 addresses.
  + https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html
**** [[./terraform/network.tf]]
:PROPERTIES:
  :header-args: :tangle terraform/network.tf
  :END:
+ Create a peering connection request from the master VPC.
+ Create a peering connection acceptor from the worker VPC.
#+begin_src json
#Initiate Peering connection request from us-east-1
resource "aws_vpc_peering_connection" "useast1-uswest2" {
  provider    = aws.region-master
  peer_vpc_id = aws_vpc.vpc_master_oregon.id
  vpc_id      = aws_vpc.vpc_master.id
  peer_region = var.region-worker

}
#Accept VPC peering request in us-west-2 from us-east-1
resource "aws_vpc_peering_connection_accepter" "accept_peering" {
  provider                  = aws.region-worker
  vpc_peering_connection_id = aws_vpc_peering_connection.useast1-uswest2.id
  auto_accept               = true
}
#+end_src
*** Create Routing in and between VPCs :route:vpc:
- A route table contains a set of rules, called routes, that are used to determine where network traffic from your subnet or gateway is directed.
  + https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html
**** [[./terraform/network.tf]]
:PROPERTIES:
  :header-args: :tangle terraform/network.tf
  :END:
+ create a routing table for the master VPC
  - to internet via ~aws_internet_gateway.igw.id~
  - to the worker VPC Peering Connection created in:  [[*Create Peering between VPCs][Create Peering between VPCs]]
+ replace default route of the master VPC with the routing table created above
+ create routing table for worker VPC
  - to internet via ~aws_internet_gateway.igw.id~
  - to the master VPC Peering Connection created in:  [[*Create Peering between VPCs][Create Peering between VPCs]]
+ replace default route of the worker VPC with the routing table created above
#+begin_src json
#Create route table in us-east-1
resource "aws_route_table" "internet_route" {
  provider = aws.region-master
  vpc_id   = aws_vpc.vpc_master.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw.id
  }
  route {
    cidr_block                = "192.168.1.0/24"
    vpc_peering_connection_id = aws_vpc_peering_connection.useast1-uswest2.id
  }
  lifecycle {
    ignore_changes = all
  }
  tags = {
    Name = "Master-Region-RT"
  }
}
#Overwrite default route table of VPC(Master) with our route table entries
resource "aws_main_route_table_association" "set-master-default-rt-assoc" {
  provider       = aws.region-master
  vpc_id         = aws_vpc.vpc_master.id
  route_table_id = aws_route_table.internet_route.id
}
#Create route table in us-west-2
resource "aws_route_table" "internet_route_oregon" {
  provider = aws.region-worker
  vpc_id   = aws_vpc.vpc_master_oregon.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw-oregon.id
  }
  route {
    cidr_block                = "10.0.1.0/24"
    vpc_peering_connection_id = aws_vpc_peering_connection.useast1-uswest2.id
  }
  lifecycle {
    ignore_changes = all
  }
  tags = {
    Name = "Worker-Region-RT"
  }
}
#Overwrite default route table of VPC(Worker) with our route table entries
resource "aws_main_route_table_association" "set-worker-default-rt-assoc" {
  provider       = aws.region-worker
  vpc_id         = aws_vpc.vpc_master_oregon.id
  route_table_id = aws_route_table.internet_route_oregon.id
}
#+end_src
*** Create Security Groups :security_groups:
- A security group acts as a virtual firewall for your instance to control inbound and outbound traffic.
  + https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html
**** [[./terraform/security_groups.tf]]
:PROPERTIES:
:header-args: :tangle terraform/security_groups.tf
:END:
+ create a SG for the: TODO Application Load Balancer TODO
  - allow in from 80/443 web ports.
  - allow out anywhere for ephemeral ports.
+ create a security group for devops in VPC Master
  - allow in from 80/443 web ports.
  - allow out anywhere for ephemeral ports.
  - allow ssh from port 22 from our home IP
  - allow in from us-west-2 (worker) subnet created in  [[*Create Subnets in our VPCs][Create Subnets in our VPCs]]
+ create a security group for devops in VPC worker
  - allow in from 80/443 web ports.
  - allow out anywhere for ephemeral ports.
  - allow ssh from port 22 from our home IP
  - allow in from us-east-1 (master) subnet created in  [[*Create Subnets in our VPCs][Create Subnets in our VPCs]]
#+begin_src json
#Create SG for LB, only TCP/80,TCP/443 and outbound access
resource "aws_security_group" "lb-sg" {
  provider    = aws.region-master
  name        = "lb-sg"
  description = "Allow 443 and traffic to devops SG"
  vpc_id      = aws_vpc.vpc_master.id
  ingress {
    description = "Allow 443 from anywhere"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  ingress {
    description = "Allow 80 from anywhere for redirection"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
#Create SG for allowing TCP/8080 from * and TCP/22 from your IP in us-east-1
resource "aws_security_group" "devops-sg" {
  provider    = aws.region-master
  name        = "devops-sg"
  description = "Allow TCP/8080 & TCP/22"
  vpc_id      = aws_vpc.vpc_master.id
  ingress {
    description = "Allow 22 from our public IP"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = [var.external_ip]
  }
  ingress {
    description     = "allow anyone on port 8080"
    from_port       = 8080
    to_port         = 8080
    protocol        = "tcp"
    security_groups = [aws_security_group.lb-sg.id]
  }
  ingress {
    description = "allow traffic from us-west-2"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["192.168.1.0/24"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
#Create SG for allowing TCP/22 from your IP in us-west-2
resource "aws_security_group" "devops-sg-oregon" {
  provider = aws.region-worker

  name        = "devops-sg-oregon"
  description = "Allow TCP/8080 & TCP/22"
  vpc_id      = aws_vpc.vpc_master_oregon.id
  ingress {
    description = "Allow 22 from our public IP"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = [var.external_ip]
  }
  ingress {
    description = "Allow traffic from us-east-1"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["10.0.1.0/24"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
#+end_src
** Create IAM Role for EC2 Access :ec2:iam:
*** [[./terraform/iam.tf]] :aws_iam_role:
:PROPERTIES:
:header-args: :tangle terraform/iam.tf
:END:
#+begin_src json
resource "aws_iam_role" "test_role" {
  name = "test_role"
  provider                    = aws.region-master
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ec2.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
  tags = {
      tag-key = "tag-value"
  }
}
#+end_src
*** [[./terraform/iam.tf]] :aws_iam_instance_profile:
:PROPERTIES:
:header-args: :tangle terraform/iam.tf
:END:
#+begin_src json
resource "aws_iam_instance_profile" "test_profile" {
  name = "test_profile"
 provider                    = aws.region-master
  role = "${aws_iam_role.test_role.name}"
}
#+end_src
*** [[./terraform/iam.tf]] :aws_iam_role_policy:
:PROPERTIES:
:header-args: :tangle terraform/iam.tf
:END:
#+begin_src json
resource "aws_iam_role_policy" "test_policy" {
  name = "test_policy"
provider                    = aws.region-master
  role = "${aws_iam_role.test_role.id}"

  policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": [
        "s3:*",
        "ec2:*"
      ],
      "Effect": "Allow",
      "Resource": "*"
    }
  ]
}
EOF
}
#+end_src
** Create Instances
*** Get AMIs :ami:vm:
- An Amazon Machine Image (AMI) provides the information required to launch an instance.
  + https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html
**** [[./terraform/instances.tf]]
:PROPERTIES:
:header-args: :tangle terraform/instances.tf
:END:
+ data
  - get the AMI names for the latest Amazon Linux AMI
  - store this as linuxAmi and linuxAmiOregon
  - can later be accessed with: ~data.aws_ssm_parameter.linuxAmi.value~
#+begin_src json
#Get Linux AMI ID using SSM Parameter endpoint in us-east-1
data "aws_ssm_parameter" "linuxAmi" {
  provider = aws.region-master
  name     = "/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2"
}
#Get Linux AMI ID using SSM Parameter endpoint in us-west-2
data "aws_ssm_parameter" "linuxAmiOregon" {
  provider = aws.region-worker
  name     = "/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2"
}
#+end_src
*** Set cloud-init Scripts
**** [[./terraform/instances.tf]]
:PROPERTIES:
:header-args: :tangle terraform/instances.tf
:END:
+ data
  - store cloud-init as data to pass to EC2 for boostrapping
#+begin_src json
data "template_file" "user_data" {
  template = file("./scripts/cloud-init.yaml")
}
#+end_src
*** Configure SSH keypairs for AMI VMs :keypair:
- A key pair, consisting of a public key and a private key, is a set of security credentials that you use to prove your identity when connecting to an Amazon EC2 instance. Amazon EC2 stores the public key on your instance, and you store the private key. For Linux instances, the private key allows you to securely SSH into your instance. Anyone who possesses your private key can connect to your instances, so it's important that you store your private key in a secure place.
  + [[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html][EC2 Keypairs]]
**** [[./terraform/instances.tf]]
:PROPERTIES:
:header-args: :tangle terraform/instances.tf
:END:
+ assign keypairs for each region from [[./terraform/ssh/id_rsa.pub]]
#+begin_src json
#Create key-pair for logging into EC2 in us-east-1
resource "aws_key_pair" "master-key" {
  provider = aws.region-master
  key_name = "devops"
  public_key = file("ssh/id_rsa.pub")
}
#Create key-pair for logging into EC2 in us-west-2
resource "aws_key_pair" "worker-key" {
  provider = aws.region-worker
  key_name = "devops"
  public_key = file("ssh/id_rsa.pub")
}
#+end_src
*** Create EC2 Instances :ec2:
- Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.
  + [[https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&ec2-whats-new.sort-order=desc][AWS EC2]]
**** [[./terraform/instances.tf]]
:PROPERTIES:
:header-args: :tangle terraform/instances.tf
:END:
#+begin_src json
#Create and bootstrap EC2 in us-east-1
resource "aws_instance" "devops-master" {
  provider                    = aws.region-master
  ami                         = data.aws_ssm_parameter.linuxAmi.value
  instance_type               = var.instance-type
  key_name                    = aws_key_pair.master-key.key_name
  associate_public_ip_address = true
  vpc_security_group_ids      = [aws_security_group.devops-sg.id]
  subnet_id                   = aws_subnet.subnet_1.id
  user_data                   = data.template_file.user_data.rendered
  iam_instance_profile = "${aws_iam_instance_profile.test_profile.name}"
  tags = {
    Name = "devops_master_tf"
  }
  depends_on = [aws_main_route_table_association.set-master-default-rt-assoc]
}
#Create EC2 in us-west-2
resource "aws_instance" "devops-worker-oregon" {
  provider                    = aws.region-worker
  count                       = var.workers-count
  ami                         = data.aws_ssm_parameter.linuxAmiOregon.value
  instance_type               = var.instance-type
  key_name                    = aws_key_pair.worker-key.key_name
  associate_public_ip_address = true
  vpc_security_group_ids      = [aws_security_group.devops-sg-oregon.id]
  subnet_id                   = aws_subnet.subnet_1_oregon.id
  tags = {
    Name = join("_", ["devops_worker_tf", count.index + 1])
  }
  depends_on = [aws_main_route_table_association.set-worker-default-rt-assoc, aws_instance.devops-master]
}
#+end_src
** S3 :s3:
:PROPERTIES:
:CUSTOM_ID: -create-infrastructure-with-terraform-s3-
:END:
- Attaching an S3 bucket to hold  miscellaneous data that may be needed during/post provisioning.
*** [[./terraform/s3.tf]] :aws_s3:
:PROPERTIES:
:header-args: :tangle terraform/s3.tf
:END:
#+begin_src json
resource "aws_s3_bucket" "misc-data" {
  provider  = aws.region-master
  bucket    = "hilgendorf-misc-data"
  acl       = "private"

  tags = {
    Name        = "misc data"
  }
}
#+end_src
- Currently getting error when creating, seemingly unable to add/list tags, commenting out until further investigation.
  + error:
    Error: error updating S3 Bucket (hilgendorf-misc-data) tags: error listing resource tags (hilgendorf-misc-data): AccessDenied: Access Denied status code: 403, request id: TR6J0XR2TT65SF3N, host id: 53e1UhXXF/V7BXwyudSim+1LG895eIc0dL2+5RDVA7lRdjmxzuzyKDb7eCGCgFlGGEMNHGOBwsM=
    with aws_s3_bucket.misc-data
    on s3.tf line 1, in resource "aws_s3_bucket" "misc-data":

    resource "aws_s3_bucket" "misc-data" {
  + Issue was due to *IAM*, policy updated [[*Create IAM User and Policies][Create IAM User and Policies]] but need to further refine. This worked after giving ~"s3:*"~ to ~terraform-user~
** Create EFS :efs:
*** [[./terraform/efs.tf]]
:PROPERTIES:
:header-args: :tangle terraform/efs.tf
:END:
#+begin_src json
resource "aws_efs_file_system" "dev" {
  creation_token = "dev-volume"
  provider  = aws.region-master
  tags = {
    Name = "keys"
  }
}
#+end_src
** ECS for AWX :awx:ecs:
:PROPERTIES:
:CUSTOM_ID: -create-infrastructure-with-terraform-ecs-for-awx-
:END:
- An Amazon ECS service allows you to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. If any of your tasks should fail or stop for any reason, the Amazon ECS service scheduler launches another instance of your task definition to replace it in order to maintain the desired number of tasks in the service.
*** ECR :ecr:
- Need to create an ECR to store our [[#-configuration-management-with-ansible-awx-][AWX]] image.
**** [[./terraform/policies/terraform_user.json]]
:PROPERTIES:
:header-args: :tangle terraform/policies/terraform_user.json
:END:
- Need ECR access to create the repository.
#+begin_src json
        "ecr:*",
#+end_src
**** [[./terraform/ecr.tf]]
:PROPERTIES:
:header-args: :tangle terraform/ecr.tf
:END:
#+begin_src json
resource "aws_ecr_repository" "images" {
  name                 = "docker_images"
  image_tag_mutability = "MUTABLE"
  region = var.region-master

  image_scanning_configuration {
    scan_on_push = true
  }
}
#+end_src
*** ECS _untangled_ :ecs:
**** [[./terraform/policies/terraform_user.json]]
:PROPERTIES:
:header-args: :tangle terraform/policies/terraform_user.json
:END:
#+begin_src json
        "elasticfilesystem:*",
#+end_src
**** [[./terraform/ecs.tf]]
:PROPERTIES:
:header-args: :tangle no
:END:
#+begin_src json
resource "aws_ecs_service" "mongo" {
  name            = "mongodb"
  cluster         = aws_ecs_cluster.foo.id
  task_definition = aws_ecs_task_definition.mongo.arn
  desired_count   = 3
  iam_role        = aws_iam_role.foo.arn
  depends_on      = [aws_iam_role_policy.foo]

  ordered_placement_strategy {
    type  = "binpack"
    field = "cpu"
  }

  load_balancer {
    target_group_arn = aws_lb_target_group.foo.arn
    container_name   = "mongo"
    container_port   = 8080
  }

  placement_constraints {
    type       = "memberOf"
    expression = "attribute:ecs.availability-zone in [us-west-2a, us-west-2b]"
  }
}
#+end_src
** Create Outputs :output:
*** [[./terraform/outputs.tf]] :outputs:
:PROPERTIES:
:header-args: :tangle terraform/outputs.tf
:END:
#+begin_src json
output "Devops-Main-Node-Public-IP" {
  value = aws_instance.devops-master.public_ip
}

output "Devops-Worker-Public-IPs" {
  value = {
    for instance in aws_instance.devops-worker-oregon :
    instance.id => instance.public_ip
  }
}
#+end_src
* Bootstrap EC2 with cloud-init :cloud_init:
- https://cloudinit.readthedocs.io/en/latest/
- https://cloudinit.readthedocs.io/en/latest/topics/examples.html
** [[./terraform/scripts/cloud-init.yaml]] :cloudinit:script:
:PROPERTIES:
:header-args: :tangle terraform/scripts/cloud-init.yaml
:END:
+ install software
+ create users
+ jenkins-master will also be ansible master
+ create ssh key
+ copy it to ec2-user known keys
#+begin_src yaml
#cloud-config
package_update: true
package_upgrade: true
packages:
  - awscli
  - tmux
  - ansible
  - git
  - python3
  - python3-pip
  - python-boto3
runcmd:
  - aws --version
  - echo "cathead-biscuit"
  - yum update -y
  - amazon-linux-extras install ansible2
  - ansible --version
  - git clone https://github.com/edhilgendorf/ansible-cloud.git
  - pip3 install boto3
  - sudo mkdir -p /opt/ansible/inventory
#+end_src
** [[./terraform/scripts/cloud-init.yaml]] :cloudinit:script:
:PROPERTIES:
:header-args: :tangle terraform/scripts/cloud-init.yaml
:END:
- We need to get public SSH keys synced from master. Current plan is to add IAM ([[*Create IAM Role for EC2 Access][Create IAM Role for EC2 Access]]) roles to the EC2 instances so they can add and download keys via AWS CLI ([[*Use AWS CLI][Use AWS CLI]])
* Configuration Management with Ansible :ansible:
- This will be focused on a new repository: [[https://github.com/edhilgendorf/ansible-cloud.git][ansible-cloud]]
- From here we will provision all agent EC2 instances created in [[*Create Infrastructure with Terraform][Create Infrastructure with Terraform]] with Ansible, starting with Jenkins
** +Getting AWS Credentials to Ansible+ This is best configured by attaching a role to the EC2 instance, done here: [[*Create IAM Role for EC2 Access][Create IAM Role for EC2 Access]]
- Local AWS access via [[https://aws.amazon.com/cli/][AWS CLI]] must be configured prior to this point, so we are going to leverage those credentials to get them into place on the EC2 server so we are able to build and maintain our [[*Dynamic Inventory][Dynamic Inventory]].
- To do this we will need to run a local script, *after* Terraform provisioning is complete.
*** [[./terraform/sync-aws-creds.sh]]
:PROPERTIES:
:header-args: :tangle ./terraform/sync-aws-creds.sh
:END:
#+begin_src json
rsync -vaP ~/.aws/credentials ec2-user@$(terraform output -json | jq  -r '."Jenkins-Main-Node-Public-IP"."value"'):/tmp/credentials
#+end_src
** Dynamic Inventory :dynamic_inventory:
https://aws.amazon.com/blogs/apn/getting-started-with-ansible-and-dynamic-amazon-ec2-inventory-management/
*** [[../ansible-cloud/ansible.cfg]]
- enable the aws_ec2 plugin
- set the inventory file to our dynamic inventory
- set remote_user
:PROPERTIES:
:header-args: :tangle ../ansible-cloud/ansible.cfg
:END:
#+begin_src
[inventory]
enable_plugins = aws_ec2
[defaults]
inventory = /ansible-cloud/ansible-inventory.yml
#+end_src
*** [[../ansible-cloud/aws_ec2.yml]]
:PROPERTIES:
:header-args: :tangle ../ansible-cloud/aws_ec2.yml
:END:
#+begin_src yml
---
plugin: aws_ec2
keyed_groups:
  - key: tags
    prefix: tag
#+end_src
** AWX :awx:
:PROPERTIES:
:CUSTOM_ID: -configuration-management-with-ansible-awx-
:END:
* IAM Terraform User _end_ :policy_end:
:PROPERTIES:
:CUSTOM_ID: -iam-terraform-user--end--
:END:
** [[./terraform/policies/terraform_user.json]]
:PROPERTIES:
:header-args: :tangle terraform/policies/terraform_user.json
:END:
#+begin_src json
      ],
      "Effect": "Allow",
      "Resource": "*"
    }
  ]
}
#+end_src
* Useful Commands
- ~taint~: taint a resource to be replaced. This might be useful to retest a cloud-init script without recreating all of your infrastructure.
  + ex: ~terraform taint aws_instance.jenkins-master~
- execute a remote command to your EC2 instance
  #+begin_src sh
ssh -o StrictHostKeyChecking=no ec2-user@$(terraform output -json | jq  -r '."Devops-Main-Node-Public-IP"."value"') "sudo grep 'cathead' /var/log/cloud-init-output.log"
  #+end_src
- ssh to your EC2 instance
  #+begin_src sh
ssh -o StrictHostKeyChecking=no ec2-user@$(terraform output -json | jq  -r '."Devops-Main-Node-Public-IP"."value"')
  #+end_src
- get IP of an instance
  #+begin_src sh
terraform output -json | jq  -r '."Devops-Main-Node-Public-IP"."value"'
  #+end_src
* Troubleshooting :troubleshooting:
** Encoded Messages :sts:error:
- You can get an error message from AWS, in Terraform output in an encoded message. You can decode this on the CLI:
  + note: may need to apply ~sts:~ to your user's role to view the contents.
#+begin_src bash
aws sts decode-authorization-message --encoded-message "<your message here>"
#+end_src
** Unrelated Errors :error:region:
- While creating and attaching the EC2 Role's I was repeatedly getting an error saying "Region must be set". I troubleshot this for days until I finally realized what was really happening -- The Terraform user (part of IAM) did not have permission to create IAM roles. After updating that role the region error disappeared. Always check your policy when adding new resources to ensure it is allowed and prevent wasting time.
